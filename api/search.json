[{"id":"c3bb980dd99e420748682f824a1ae74e","title":"手写数字识别","content":"餐前祷告怎么才能让你的电脑有那么一丢丢的小智能呢，现在好像有好多方法，但是那些高大上的方法，好像我们现在难以自己去实现，不过嘛万丈高楼平地起，我们可以用我们的聪明才智来实现一些小小的智能。\n基础理论  那么我们就从手写数字识别开始吧！\n  我们都知道人工智能三要素是什么呢？数据、算法、计算资源。现在呢我们需要第一个东西“数据”。那数据在哪呢，原遇到，等等，楼门口来前辈们为我们贴心的准备好了，他就藏在一个叫keras的库里面。那么数据解决了算法呢？算法自在心中，下面就让我来细细说说吧。\n  这里呢我们就用一个结构简单，且易于理解的CNN卷积神经网络。什么！CNN！不就是那个图里面一层一层好复杂的东西吗？比如下面这个东西。莫怕莫怕，且听我细细道来\n\n   其实呢，抛去那些晦涩难懂的概念，细说CNN的构成就那么几层罢了，卷积层、激活函数、池化层、全连接层。我们这里打算仅搭建四层，进行这个让我们的电脑成为一个“小超人”这个神圣的任务。第一层：卷积层 、第二层：卷积层、 第三层：全连接层、 第四层：输出层。\n\n  我们的数据集呢「1」，文末介绍。我们建立这些层的原因是什么呢？这要从卷积神经网络的原理说起，即对图片的特征进行提取，我们现在第二个卷积层窗口大小为5×5，对32张图像求卷积产生64个特征图，参数个数是 5×5×32×64=51200个权值加上64个偏置。\n\n   池化计算是在卷积层中进行的，使用2×2，步长为2的池化窗口做池化计算，池化后得到64张7×7的特征图。特征图长宽都变成了之前的1/2。\n\n   第三层是全连接层，为池化层的结果做池化计算，池化后得到特征图。\n\n    第四层是输出层，输出预测值。\n\n   **特征图数量越多**说明卷积网络提取的**特征数量越多**，如果特征图数量设置得**太少**容易出现**欠拟合**，如果特征图数量设置得**太多**容易出现**过拟合**，所以需要设置为合适的数值。 \n\n开始搭建神经网络引入数据集这里呢我们引入数据集是一个非常简单的事情，只需要导入keras.datasets下的mnist即可。\nmnist &#x3D; tf.keras.datasets.mnist\n(train_data,traini_target), (test_data,test_target) &#x3D; mnist.load_data() \n\n\n\n数据预处理这里我们要使用TensorFlow来进行后续操作，所以需要先对数据进行处理。\ntrain_data &#x3D; train_data.reshape(-1, 28, 28, 1)\ntest_data &#x3D; test_data.reshape(-1, 28, 28, 1)\n\ntrain_data &#x3D; train_data&#x2F;255.0\ntest_data &#x3D; test_data&#x2F;255.0\n\ntrain_target &#x3D; tf.keras.utils.to_categorical(train_target, num_classes&#x3D;10)\ntest_target &#x3D; tf.keras.utils.to_categorical(test_target, num_classes&#x3D;10)    #10种结果\n\n搭建网络卷积层的搭建这一层主要是由卷积层+池化层组成，在tensorflow中为我们直接提供了函数。\nmodel.add(Convolution2D(input_shape &#x3D; (28,28,1), filters &#x3D; 32, kernel_size &#x3D; 5, strides &#x3D; 1, padding &#x3D; &#39;same&#39;, activation &#x3D; &#39;relu&#39;))\n\nmodel.add(MaxPooling2D(pool_size &#x3D; 2, strides &#x3D; 2, padding &#x3D; &#39;same&#39;,))\n\n第二个卷积层model.add(Convolution2D(64, 5, strides&#x3D;1, padding&#x3D;&#39;same&#39;, activation&#x3D;&#39;relu&#39;))\n\nmodel.add(MaxPooling2D(2, 2, &#39;same&#39;))\n\nmodel.add(Flatten())\n\n第一个全连接层model.add(Dense(1024,activation &#x3D; &#39;relu&#39;))\nmodel.add(Dropout(0.5))\n\n第二个全连接层（输出层）model.add(Dense(10, activation&#x3D;&#39;softmax&#39;))\n\n编译model.compile(optimizer&#x3D;Adam(lr&#x3D;1e-4), loss&#x3D;&#39;categorical_crossentropy&#39;, metrics&#x3D;[&#39;accuracy&#39;])\n\n训练与保存model.fit(train_data, train_target, batch_size&#x3D;64, epochs&#x3D;10, validation_data&#x3D;(test_data, test_target))\nmodel.save(&quot;mnist.h5&quot;)\n\n# 手写数字识别 -- CNN神经网络训练\nimport os\nos.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;]&#x3D;&#39;2&#39;\n \nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout,Convolution2D,MaxPooling2D,Flatten\nfrom tensorflow.keras.optimizers import Adam\n \n# 1、载入数据\nmnist &#x3D; tf.keras.datasets.mnist\n(train_data, train_target), (test_data, test_target) &#x3D; mnist.load_data()\n \n# 2、改变数据维度\ntrain_data &#x3D; train_data.reshape(-1, 28, 28, 1)\ntest_data &#x3D; test_data.reshape(-1, 28, 28, 1)\n# 注：在TensorFlow中，在做卷积的时候需要把数据变成4维的格式\n# 这4个维度分别是：数据数量，图片高度，图片宽度，图片通道数\n \n# 3、归一化（有助于提升训练速度）\ntrain_data &#x3D; train_data&#x2F;255.0\ntest_data &#x3D; test_data&#x2F;255.0\n \n# 4、独热编码\ntrain_target &#x3D; tf.keras.utils.to_categorical(train_target, num_classes&#x3D;10)\ntest_target &#x3D; tf.keras.utils.to_categorical(test_target, num_classes&#x3D;10)    #10种结果\n \n# 5、搭建CNN卷积神经网络\nmodel &#x3D; Sequential()\n# 5-1、第一层：卷积层+池化层\n# 第一个卷积层\nmodel.add(Convolution2D(input_shape &#x3D; (28,28,1), filters &#x3D; 32, kernel_size &#x3D; 5, strides &#x3D; 1, padding &#x3D; &#39;same&#39;, activation &#x3D; &#39;relu&#39;))\n#         卷积层         输入数据                  滤波器数量      卷积核大小        步长          填充数据(same padding)  激活函数\n# 第一个池化层 # pool_size\nmodel.add(MaxPooling2D(pool_size &#x3D; 2, strides &#x3D; 2, padding &#x3D; &#39;same&#39;,))\n#         池化层(最大池化) 池化窗口大小   步长          填充方式\n \n# 5-2、第二层：卷积层+池化层\n# 第二个卷积层\nmodel.add(Convolution2D(64, 5, strides&#x3D;1, padding&#x3D;&#39;same&#39;, activation&#x3D;&#39;relu&#39;))\n# 64:滤波器个数      5:卷积窗口大小\n# 第二个池化层\nmodel.add(MaxPooling2D(2, 2, &#39;same&#39;))\n \n# 5-3、扁平化 （相当于把(64,7,7,64)数据-&gt;(64,7*7*64)）\nmodel.add(Flatten())\n \n# 5-4、第三层：第一个全连接层\nmodel.add(Dense(1024, activation &#x3D; &#39;relu&#39;))\nmodel.add(Dropout(0.5))\n \n# 5-5、第四层：第二个全连接层（输出层）\nmodel.add(Dense(10, activation&#x3D;&#39;softmax&#39;))\n# 10：输出神经元个数\n \n# 6、编译\nmodel.compile(optimizer&#x3D;Adam(lr&#x3D;1e-4), loss&#x3D;&#39;categorical_crossentropy&#39;, metrics&#x3D;[&#39;accuracy&#39;])\n#            优化器(adam)               损失函数(交叉熵损失函数)            标签\n \n# 7、训练\nmodel.fit(train_data, train_target, batch_size&#x3D;64, epochs&#x3D;10, validation_data&#x3D;(test_data, test_target))\n \n# 8、保存模型\nmodel.save(&#39;mnist.h5&#39;)\n\n","slug":"手写数字识别","date":"2022-10-28T09:34:49.621Z","categories_index":"算法","tags_index":"人工智能","author_index":"Gaoth"},{"id":"79e698f73bf1620cec8c00ca6b6e07dc","title":"Leetcode1024活动的小小解密","content":"开始的开始今年的LeetCode 1024活动是一个非常有意思的活动，名字是1024马尔可夫链，活动规则很好理解，就是一个马尔可夫链嘛。马尔可夫链（Markov Chain）可以说是机器学习和人工智能的基石，在强化学习、自然语言处理、金融领域、天气预测、语音识别方面都有着极其广泛的应用，去年的1024活动是人生重开模拟，这和去年的小游戏又有了一定的联系，人生不会重来，只会不断向前。\n\n\n\n\n\n\n\n\n\nThe future is independent of the past given the present未来独立于过去，只基于当下。\n这句人生哲理的话也代表了马尔科夫链的思想：过去所有的信息都已经被保存到了现在的状态，基于现在就可以预测未来。这里呢不再过多赘述，下面就让我们来介绍一下这个小游戏吧。\n游戏规则\n\n\n\n\n\n\n\n\n用 7 张牌进行 3 次运算，其中每次运算需使用 2 张 数字牌 和 1 张 运算符号牌 ；\n\n\n\n\n\n\n\n\n\n每次运算后都将根据上一次的运算结果生成一张数字牌。最后一次运算结果刚好等于 1024 时记为「成功」。但是这里，每一步运算是无法撤销的！所以我们应该将我们的下一步考虑好再进行下一步。\n\n我们每天做题、登陆都是可以获得一定的卡片的。\n做题！怎么利用自己的手来做出这个题目呢？我们可以先进行观察，首先我们是利用手中的所有卡片来进行 排序的。依我拙见，由于本人算法能力有些弱，所以呢自己写了个回溯全排，来解决这个问题。（这也就是不是个题目，要是个题目我这解法估计能超时超到家了）\n下面附上我的傻瓜代码：\n# 定义一个全排列函数\n# 应该一个数字加一个字母进行运算\n# 存在的问题：\n#   1.存在符号之间的转化 ------&gt; 选择使用eval()或直接读\n#   2.全排中加入符号  ------&gt; 先加数字在选两个符号\n\ndef dfs(p_, ans, length, s):\n    if len(ans) &#x3D;&#x3D; length:\n        if s &#x3D;&#x3D; &quot;int&quot;:\n            result_num.append(ans)\n        else:\n            result_operator.append(ans)\n        return\n    else:\n        for i in range(len(p_)):\n            dfs(p_[:i] + p_[i + 1:], ans + [p_[i]], length, s)\n\n\nresult_num &#x3D; list(set(result_num))\n\n\ndef main():\n    dfs(num, [], 4, &quot;int&quot;)\n    dfs(operoter, [], 3, &quot; &quot;)\n    res_ans &#x3D; []\n    if len(result_operator[0]) &lt; 3 or len(result_num[0]) &lt; 4:\n        print(&quot;抱歉，没有合适组合，请您继续努力&quot;)\n        return False\n    for i in range(len(result_num)):\n        result_num[i] &#x3D; list(map(str, result_num[i]))\n        for j in range(len(result_operator)):\n            res_str &#x3D; f&quot;((&#123;result_num[i][0]&#125;&#123;result_operator[j][0]&#125;&#123;result_num[i][1]&#125;)&#123;result_operator[j][1]&#125;&#123;result_num[i][2]&#125;) &#123;result_operator[j][2]&#125;&#123;result_num[i][3]&#125; &quot;\n            if eval(res_str) &#x3D;&#x3D; 1024:\n                res_ans.append(res_str)\n    print(res_ans)\n\n\nif __name__ &#x3D;&#x3D; &quot;__main__&quot;:\n    main()\n\n\n最后这里引用游戏攻略里的一句话 “往事止于此，未来始于斯” 。祝福各位开可以以今日之我，成就明日生活。\n","slug":"LeetCode1024活动的解谜之道 60f600fc-dc00-4ffe-ba43-30dc8c6db45f","date":"2022-10-28T09:34:35.138Z","categories_index":"算法","tags_index":"算法","author_index":"Gaoth"},{"id":"7fddf81bf2759d3c5373d8e9a24289e5","title":"ArchLinux软件包管理器--pacman","content":"本文多含自娱自乐内容，本意为方便作者查看，仅针对作者个人对于pacman的使用方法。且具体教程wiki以明确给出。\n引言就在前几天一不小心就把自己的系统换成了ArchLinux，那我们都知道Ubuntu的软件包管理器是apt-get，那ArchLinux呢？没错就是Pacman。\nPacman是ArchLinux的一个亮点，安装软件是真的方便，而不论他们来自于官方的Arch软件库或是用户自己创建的。\n\n\n\n\n\n\n\n\n\nPacman可以通过和主服务器同步包列表来进行系统更新，这使得注重安全的系统管理员的维护工作成为轻而易举的事情。——ArchLinux wiki\n常用操作安装指定包Textpacman -S package_name1 package_name2\n\n删除指定包删除单个软件包，保留其全部已经安装的依赖关系\npacman -R package_name\n\n删除指定软件包，及其所有没有被其他已安装软件包使用的依赖关系：\npacman -Rs package_name\n\n上面这条命令在移除包含其他所需包的组时有时候会拒绝运行。这种情况下可以尝试：\npacman -Rsu package_name\n\n升级软件包pacman -Syu\n\n查询包数据库pacman 使用 -Q 参数查询本地软件包数据库， -S 查询同步数据库，以及 -F查询文件数据库。要了解每个参数的子选项，分别参见 pacman -Q --help，pacman -S --help和pacman -F --help。\npacman -Ss string1 string2\n\npacman -Qs string1 string2 ...\n\npacman -F string1 string2 ...\n\n清理软件包缓存Textpaccache -r\n\nTextpacman -Sc\n或 pacman -Scc\n\n我的常用操作常用操作包括安装包、删除包、清理缓存、升级软件包、还有如下未列出命令：\nText# 安装本地包\npacman -U &#x2F;path&#x2F;to&#x2F;package&#x2F;package_name-version.pkg.tar.zst\n\n\n\n","slug":"Pacman软件包管理器介绍","date":"2022-10-28T09:33:46.536Z","categories_index":"","tags_index":"Linux","author_index":"Gaoth"},{"id":"33acdddb35650af797ecddd2d38891a7","title":"要好好学习天天向上哟","content":"鸽巢原理进行排序https://leetcode.cn/problems/missing-two-lcci/\n123for (int i=0 ; i&lt;nums.size() ; i++)&#123;\twhile(nums[i] != -1 &amp;&amp; nums[i] != i+1) swap(nums[i] , nums[nums[i]-1]);&#125;\n\n说明：此模板用于对有规律的数进行排序，核心思想是一个萝卜一个坑。\n桌上有十个苹果，要把这十个苹果放到九个抽屉里，无论怎样放，我们会发现至少会有一个抽屉里面放不少于两个苹果。这一现象就是我们所说的“抽屉原理”。 抽屉原理的一般含义为：“如果每个抽屉代表一个集合，每一个苹果就可以代表一个元素，假如有n+1个元素放到n个集合中去，其中必定有一个集合里至少有两个元素。” 抽屉原理有时也被称为鸽巢原理。本质上是对哈希定址法的改变。\n排序算法（归并排序）这里放题目\n对于归并排序我是这样理解的，对于一个未排序的数组，我们可以将其对半分开，分开后再将其按顺序合并，那么具体的合并流程呢？首先需要先创建一个新的数组（这个数组容量为两个子数组容量的和），然后将两个子数组按大小排入这个新数组中，因为我们是将小块合并所以保证在前面的数组是按照规则排序的，那么后面的只需要比较两个小数组的第一个值即可保证不错位。\n\n\nPython排序进阶（工具）https://leetcode.cn/problems/largest-number/\n我们知道Python中排序有sorted(_iterable, key, reverse),而这里我们着重来说这个“key”，这个“key”是让我们sorted()函数真正好用的关键。\n针对key我们可以用lambda:或写函数来改变，也可以通过functools模块中的cmp_to_key来对自定义的cmp函数进行包装，然后就能赋值给sorted函数的关键字参数key，来间接实现Python2中cmp函数用于排序的效果。\nPython排序进阶(2)（工具）https://leetcode.cn/problems/advantage-shuffle/\nPython中还提供了一个排序的库（sortedcontainers）。\n这个库提供了三个类：SortedList 、SortedDict、SortedSet。我们可以直接声明一个SortedList对象，这个对象会直接对列表中的值进行排序，\n123456import sortedcontainerst = sortedcontainers.SortedList([4, 2, 5, 3, 1])print(t)&gt;&gt;SortedList([1, 2, 3, 4, 5])\n\n常见的方法：add()、remove()、discard()、pop()、bisect_left()、count()。\n\n\n\n方法\n时间复杂度\n说明\n\n\n\nadd()\n近似O(logn)\n向SortedList()中添加元素\n\n\nupdate(iterable)\n近似O(k*logn)\n向SortedList()中添加列表\n\n\nclear()\nO(n)\n删除所以元素\n\n\ndiscard(value)\n近似O(logn)\n删除单个元素（元素可不存在）\n\n\nremove()\n近似O(logn)\n删除单个元素（元素不存在报错）\n\n\npop(index&#x3D;-1)\n近似O(logn)\n同列表pop\n\n\nbisect_left(value)\n近似O(logn)\n找出元素位置\n\n\ncount()\n近似O(logn)\n查找个数\n\n\nindex()\n近似O(logn)\n同列表index\n\n\nSortedList的排序方法是系统默认的，我们也可以设置排序方法，比如数值从大到小排序\n123456789from sortedcontainers import SortedListfrom operator import neg test_sl = SortedList([3,5,1,2,7,6,4], key=neg) print(test_sl) output:SortedKeyList([7, 6, 5, 4, 3, 2, 1], key=&lt;built-in function neg&gt;)\n\n1234567from sortedcontainers import SortedList test_str = SortedList([&quot;1&quot;, &quot;431&quot;, &quot;34&quot;], key=lambda item:len(item))print(test_str) output:SortedKeyList([&#x27;1&#x27;, &#x27;34&#x27;, &#x27;431&#x27;], key=&lt;function &lt;lambda&gt; at 0x7fb883b36820&gt;)\n\n\n\n回溯（全排列）模板https://leetcode.cn/problems/permutations/\n题目分析：就这道题目而言，因其不包含重复数字，故不需考虑重复问题，那么怎么样实现全排列呢？我们从小都知道，全排列要有条理的从原列表中一个个拿出，而拿出后我们应该将这个元素去掉！所以我们就可以有思路了。本质上我们应将数字从列表中一个个拿出这样我们可以用一层循环遍历。用“我”的浅薄装逼的表示即为：\n$f(x+1)&#x3D;f(x)+d[i]$\n解释：$f(x)$为我们要组成的结果，$d[i]$为列表中的元素。列表元素是一遍遍减少的！这个是重要的\n代码：1234567891011class Solution:    def permute(self, nums: List[int]) -&gt; List[List[int]]:        res = []        def backtracking(nums, t):            if not nums:                res.append(t)                return            for i in range(len(nums)):                backtracking(nums[:i]+nums[i+1:],t+[nums[i]])        backtracking(nums,[])        return res\n\n再说回来回溯法：采用试错的思想，它尝试分步的去解决一个问题。在分步解决问题的过程中，当它通过尝试发现现有的分步答案不能得到有效的正确的解答的时候，它将取消上一步甚至是上几步的计算，再通过其它的可能的分步解答再次尝试寻找问题的答案。回溯法通常用最简单的递归方法来实现，在反复重复上述的步骤后可能出现两种情况：\n找到一个可能存在的正确的答案；在尝试了所有可能的分步方法后宣告该问题没有答案。\n回溯算法关键在于：不合适就退回上一步，然后通过约束条件, 减少时间复杂度。其和深度搜索算法是有些相似之处的。\n","slug":"刷题不","date":"2022-10-25T12:30:21.151Z","categories_index":"算法","tags_index":"算法","author_index":"Gaoth"}]