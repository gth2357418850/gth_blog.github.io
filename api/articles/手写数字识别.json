{"title":"手写数字识别","uid":"c3bb980dd99e420748682f824a1ae74e","slug":"手写数字识别","date":"2023-03-10T09:42:48.160Z","updated":"2023-03-10T09:42:48.160Z","comments":true,"path":"api/articles/手写数字识别.json","keywords":null,"cover":"https://smms.app/image/pBkLugRUEeihwjD","content":"<h1 id=\"餐前祷告\"><a href=\"#餐前祷告\" class=\"headerlink\" title=\"餐前祷告\"></a>餐前祷告</h1><p>怎么才能让你的电脑有那么一丢丢的小智能呢，现在好像有好多方法，但是那些高大上的方法，<br>好像我们现在难以自己去实现，不过嘛万丈高楼平地起，我们可以用我们的聪明才智来实现一些<br>小小的智能。</p>\n<h1 id=\"基础理论\"><a href=\"#基础理论\" class=\"headerlink\" title=\"基础理论\"></a>基础理论</h1><p>  那么我们就从手写数字识别开始吧！</p>\n<p>  我们都知道人工智能三要素是什么呢？数据、算法、计算资源。现在呢我们需要第一个东西“数据”。那数据在哪呢，原遇到，等等，楼门口来前辈们为我们贴心的准备好了，他就藏在一个叫keras的库里面。那么数据解决了算法呢？算法自在心中，下面就让我来细细说说吧。</p>\n<p>  这里呢我们就用一个结构简单，且易于理解的CNN卷积神经网络。什么！CNN！不就是那个图里面一层一层好复杂的东西吗？比如下面这个东西。莫怕莫怕，且听我细细道来</p>\n<p><img src=\"https://s2.loli.net/2022/10/24/FlLen1Nt36PkRhV.png\" alt=\"image.png\"></p>\n<pre><code>   其实呢，抛去那些晦涩难懂的概念，细说CNN的构成就那么几层罢了，卷积层、激活函数、池化层、全连接层。我们这里打算仅搭建四层，进行这个让我们的电脑成为一个“小超人”这个神圣的任务。第一层：卷积层 、第二层：卷积层、 第三层：全连接层、 第四层：输出层。\n\n  我们的数据集呢「1」，文末介绍。我们建立这些层的原因是什么呢？这要从卷积神经网络的原理说起，即对图片的特征进行提取，我们现在第二个卷积层窗口大小为5×5，对32张图像求卷积产生64个特征图，参数个数是 5×5×32×64=51200个权值加上64个偏置。\n\n   池化计算是在卷积层中进行的，使用2×2，步长为2的池化窗口做池化计算，池化后得到64张7×7的特征图。特征图长宽都变成了之前的1/2。\n\n   第三层是全连接层，为池化层的结果做池化计算，池化后得到特征图。\n\n    第四层是输出层，输出预测值。\n\n   **特征图数量越多**说明卷积网络提取的**特征数量越多**，如果特征图数量设置得**太少**容易出现**欠拟合**，如果特征图数量设置得**太多**容易出现**过拟合**，所以需要设置为合适的数值。 \n</code></pre>\n<h1 id=\"开始搭建神经网络\"><a href=\"#开始搭建神经网络\" class=\"headerlink\" title=\"开始搭建神经网络\"></a>开始搭建神经网络</h1><h2 id=\"引入数据集\"><a href=\"#引入数据集\" class=\"headerlink\" title=\"引入数据集\"></a>引入数据集</h2><p>这里呢我们引入数据集是一个非常简单的事情，只需要导入<code>keras.datasets</code>下的<code>mnist</code>即可。</p>\n<pre class=\"line-numbers language-Python\" data-language=\"Python\"><code class=\"language-Python\">mnist &#x3D; tf.keras.datasets.mnist\n(train_data,traini_target), (test_data,test_target) &#x3D; mnist.load_data() <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n\n\n<h2 id=\"数据预处理\"><a href=\"#数据预处理\" class=\"headerlink\" title=\"数据预处理\"></a>数据预处理</h2><p>这里我们要使用TensorFlow来进行后续操作，所以需要先对数据进行处理。</p>\n<pre class=\"line-numbers language-Python\" data-language=\"Python\"><code class=\"language-Python\">train_data &#x3D; train_data.reshape(-1, 28, 28, 1)\ntest_data &#x3D; test_data.reshape(-1, 28, 28, 1)<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n<pre class=\"line-numbers language-Python\" data-language=\"Python\"><code class=\"language-Python\">train_data &#x3D; train_data&#x2F;255.0\ntest_data &#x3D; test_data&#x2F;255.0<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n<pre class=\"line-numbers language-Python\" data-language=\"Python\"><code class=\"language-Python\">train_target &#x3D; tf.keras.utils.to_categorical(train_target, num_classes&#x3D;10)\ntest_target &#x3D; tf.keras.utils.to_categorical(test_target, num_classes&#x3D;10)    #10种结果<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n<h2 id=\"搭建网络\"><a href=\"#搭建网络\" class=\"headerlink\" title=\"搭建网络\"></a>搭建网络</h2><h3 id=\"卷积层的搭建\"><a href=\"#卷积层的搭建\" class=\"headerlink\" title=\"卷积层的搭建\"></a>卷积层的搭建</h3><p>这一层主要是由卷积层+池化层组成，在tensorflow中为我们直接提供了函数。</p>\n<pre class=\"line-numbers language-Python\" data-language=\"Python\"><code class=\"language-Python\">model.add(Convolution2D(input_shape &#x3D; (28,28,1), filters &#x3D; 32, kernel_size &#x3D; 5, strides &#x3D; 1, padding &#x3D; &#39;same&#39;, activation &#x3D; &#39;relu&#39;))\n\nmodel.add(MaxPooling2D(pool_size &#x3D; 2, strides &#x3D; 2, padding &#x3D; &#39;same&#39;,))<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n\n<h3 id=\"第二个卷积层\"><a href=\"#第二个卷积层\" class=\"headerlink\" title=\"第二个卷积层\"></a>第二个卷积层</h3><pre class=\"line-numbers language-Python\" data-language=\"Python\"><code class=\"language-Python\">model.add(Convolution2D(64, 5, strides&#x3D;1, padding&#x3D;&#39;same&#39;, activation&#x3D;&#39;relu&#39;))\n\nmodel.add(MaxPooling2D(2, 2, &#39;same&#39;))<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n\n<pre class=\"line-numbers language-Python\" data-language=\"Python\"><code class=\"language-Python\">model.add(Flatten())<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<h3 id=\"第一个全连接层\"><a href=\"#第一个全连接层\" class=\"headerlink\" title=\"第一个全连接层\"></a>第一个全连接层</h3><pre class=\"line-numbers language-Python\" data-language=\"Python\"><code class=\"language-Python\">model.add(Dense(1024,activation &#x3D; &#39;relu&#39;))\nmodel.add(Dropout(0.5))<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n<h3 id=\"第二个全连接层（输出层）\"><a href=\"#第二个全连接层（输出层）\" class=\"headerlink\" title=\"第二个全连接层（输出层）\"></a>第二个全连接层（输出层）</h3><pre class=\"line-numbers language-Python\" data-language=\"Python\"><code class=\"language-Python\">model.add(Dense(10, activation&#x3D;&#39;softmax&#39;))<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<h3 id=\"编译\"><a href=\"#编译\" class=\"headerlink\" title=\"编译\"></a>编译</h3><pre class=\"line-numbers language-Python\" data-language=\"Python\"><code class=\"language-Python\">model.compile(optimizer&#x3D;Adam(lr&#x3D;1e-4), loss&#x3D;&#39;categorical_crossentropy&#39;, metrics&#x3D;[&#39;accuracy&#39;])<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<h3 id=\"训练与保存\"><a href=\"#训练与保存\" class=\"headerlink\" title=\"训练与保存\"></a>训练与保存</h3><pre class=\"line-numbers language-Python\" data-language=\"Python\"><code class=\"language-Python\">model.fit(train_data, train_target, batch_size&#x3D;64, epochs&#x3D;10, validation_data&#x3D;(test_data, test_target))\nmodel.save(&quot;mnist.h5&quot;)<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n<pre class=\"line-numbers language-Python\" data-language=\"Python\"><code class=\"language-Python\"># 手写数字识别 -- CNN神经网络训练\nimport os\nos.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;]&#x3D;&#39;2&#39;\n \nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout,Convolution2D,MaxPooling2D,Flatten\nfrom tensorflow.keras.optimizers import Adam\n \n# 1、载入数据\nmnist &#x3D; tf.keras.datasets.mnist\n(train_data, train_target), (test_data, test_target) &#x3D; mnist.load_data()\n \n# 2、改变数据维度\ntrain_data &#x3D; train_data.reshape(-1, 28, 28, 1)\ntest_data &#x3D; test_data.reshape(-1, 28, 28, 1)\n# 注：在TensorFlow中，在做卷积的时候需要把数据变成4维的格式\n# 这4个维度分别是：数据数量，图片高度，图片宽度，图片通道数\n \n# 3、归一化（有助于提升训练速度）\ntrain_data &#x3D; train_data&#x2F;255.0\ntest_data &#x3D; test_data&#x2F;255.0\n \n# 4、独热编码\ntrain_target &#x3D; tf.keras.utils.to_categorical(train_target, num_classes&#x3D;10)\ntest_target &#x3D; tf.keras.utils.to_categorical(test_target, num_classes&#x3D;10)    #10种结果\n \n# 5、搭建CNN卷积神经网络\nmodel &#x3D; Sequential()\n# 5-1、第一层：卷积层+池化层\n# 第一个卷积层\nmodel.add(Convolution2D(input_shape &#x3D; (28,28,1), filters &#x3D; 32, kernel_size &#x3D; 5, strides &#x3D; 1, padding &#x3D; &#39;same&#39;, activation &#x3D; &#39;relu&#39;))\n#         卷积层         输入数据                  滤波器数量      卷积核大小        步长          填充数据(same padding)  激活函数\n# 第一个池化层 # pool_size\nmodel.add(MaxPooling2D(pool_size &#x3D; 2, strides &#x3D; 2, padding &#x3D; &#39;same&#39;,))\n#         池化层(最大池化) 池化窗口大小   步长          填充方式\n \n# 5-2、第二层：卷积层+池化层\n# 第二个卷积层\nmodel.add(Convolution2D(64, 5, strides&#x3D;1, padding&#x3D;&#39;same&#39;, activation&#x3D;&#39;relu&#39;))\n# 64:滤波器个数      5:卷积窗口大小\n# 第二个池化层\nmodel.add(MaxPooling2D(2, 2, &#39;same&#39;))\n \n# 5-3、扁平化 （相当于把(64,7,7,64)数据-&gt;(64,7*7*64)）\nmodel.add(Flatten())\n \n# 5-4、第三层：第一个全连接层\nmodel.add(Dense(1024, activation &#x3D; &#39;relu&#39;))\nmodel.add(Dropout(0.5))\n \n# 5-5、第四层：第二个全连接层（输出层）\nmodel.add(Dense(10, activation&#x3D;&#39;softmax&#39;))\n# 10：输出神经元个数\n \n# 6、编译\nmodel.compile(optimizer&#x3D;Adam(lr&#x3D;1e-4), loss&#x3D;&#39;categorical_crossentropy&#39;, metrics&#x3D;[&#39;accuracy&#39;])\n#            优化器(adam)               损失函数(交叉熵损失函数)            标签\n \n# 7、训练\nmodel.fit(train_data, train_target, batch_size&#x3D;64, epochs&#x3D;10, validation_data&#x3D;(test_data, test_target))\n \n# 8、保存模型\nmodel.save(&#39;mnist.h5&#39;)<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n","feature":true,"text":"餐前祷告怎么才能让你的电脑有那么一丢丢的小智能呢，现在好像有好多方法，但是那些高大上的方法，好像我们现在难以自己去实现，不过嘛万丈高楼平地起，我们可以用我们的聪明才智来实现一些小小的智能。 基础理论 那么我们就从手写数字识别开始吧！ 我们都知道人工智能三要素是什么呢？数据、算法、...","link":"","photos":[],"count_time":{"symbolsCount":"4.6k","symbolsTime":"4 mins."},"categories":[{"name":"算法","slug":"算法","count":4,"path":"api/categories/算法.json"}],"tags":[{"name":"人工智能","slug":"人工智能","count":1,"path":"api/tags/人工智能.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E9%A4%90%E5%89%8D%E7%A5%B7%E5%91%8A\"><span class=\"toc-text\">餐前祷告</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA\"><span class=\"toc-text\">基础理论</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\"><span class=\"toc-text\">开始搭建神经网络</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%BC%95%E5%85%A5%E6%95%B0%E6%8D%AE%E9%9B%86\"><span class=\"toc-text\">引入数据集</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86\"><span class=\"toc-text\">数据预处理</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C\"><span class=\"toc-text\">搭建网络</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%8D%B7%E7%A7%AF%E5%B1%82%E7%9A%84%E6%90%AD%E5%BB%BA\"><span class=\"toc-text\">卷积层的搭建</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%AC%AC%E4%BA%8C%E4%B8%AA%E5%8D%B7%E7%A7%AF%E5%B1%82\"><span class=\"toc-text\">第二个卷积层</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82\"><span class=\"toc-text\">第一个全连接层</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%AC%AC%E4%BA%8C%E4%B8%AA%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%EF%BC%88%E8%BE%93%E5%87%BA%E5%B1%82%EF%BC%89\"><span class=\"toc-text\">第二个全连接层（输出层）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%BC%96%E8%AF%91\"><span class=\"toc-text\">编译</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%AE%AD%E7%BB%83%E4%B8%8E%E4%BF%9D%E5%AD%98\"><span class=\"toc-text\">训练与保存</span></a></li></ol></li></ol></li></ol>","author":{"name":"Gaoth","slug":"gaoth","avatar":"https://s2.loli.net/2022/10/24/zZ5Msr7bhigQVcj.jpg","link":"/","description":"不以为然的存在，细品起来会得到意想不到的有趣。<br /> @<b>公众号：噜啦啦小栈</b>","socials":{"github":"https://github.com//githubforgth","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/m0_51898303","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"Django入门————初步认识","uid":"c445c962a5187b343c212608e3c50f71","slug":"Django入门————初步认识","date":"2024-02-22T09:03:13.000Z","updated":"2024-02-22T09:29:52.897Z","comments":true,"path":"api/articles/Django入门————初步认识.json","keywords":null,"cover":"https://s2.loli.net/2024/02/22/Qwo7xFNGtuPK2Eh.png","text":" Django是一个强大的Python Web框架，主要用于快速开发复杂的数据库驱动的网站。 前期知识Django 的特点： ORM： Django 有一套强大的 ORM ，运行开发者通过 Python 代码来对数据库模型进行操作，使数据库的操作变得容易。 MVC架构：Djang...","link":"","photos":[],"count_time":{"symbolsCount":"1.1k","symbolsTime":"1 mins."},"categories":[{"name":"Django","slug":"Django","count":1,"path":"api/categories/Django.json"}],"tags":[{"name":"Django","slug":"Django","count":1,"path":"api/tags/Django.json"}],"author":{"name":"Gaoth","slug":"gaoth","avatar":"https://s2.loli.net/2022/10/24/zZ5Msr7bhigQVcj.jpg","link":"/","description":"不以为然的存在，细品起来会得到意想不到的有趣。<br /> @<b>公众号：噜啦啦小栈</b>","socials":{"github":"https://github.com//githubforgth","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/m0_51898303","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"Leetcode1024活动的小小解密","uid":"79e698f73bf1620cec8c00ca6b6e07dc","slug":"LeetCode1024活动的解谜之道 60f600fc-dc00-4ffe-ba43-30dc8c6db45f","date":"2022-10-28T09:34:35.138Z","updated":"2022-10-28T09:34:35.138Z","comments":true,"path":"api/articles/LeetCode1024活动的解谜之道 60f600fc-dc00-4ffe-ba43-30dc8c6db45f.json","keywords":null,"cover":[],"text":"开始的开始今年的LeetCode 1024活动是一个非常有意思的活动，名字是1024马尔可夫链，活动规则很好理解，就是一个马尔可夫链嘛。马尔可夫链（Markov Chain）可以说是机器学习和人工智能的基石，在强化学习、自然语言处理、金融领域、天气预测、语音识别方面都有着极其广泛...","link":"","photos":[],"count_time":{"symbolsCount":"2k","symbolsTime":"2 mins."},"categories":[{"name":"算法","slug":"算法","count":4,"path":"api/categories/算法.json"}],"tags":[{"name":"算法","slug":"算法","count":5,"path":"api/tags/算法.json"}],"author":{"name":"Gaoth","slug":"gaoth","avatar":"https://s2.loli.net/2022/10/24/zZ5Msr7bhigQVcj.jpg","link":"/","description":"不以为然的存在，细品起来会得到意想不到的有趣。<br /> @<b>公众号：噜啦啦小栈</b>","socials":{"github":"https://github.com//githubforgth","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/m0_51898303","juejin":"","customs":{}}},"feature":true}}